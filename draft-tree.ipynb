{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledSet:  \n",
    "    \n",
    "    def __init__(self, input_dimension, ordinal_attributes):\n",
    "        '''\n",
    "            ordinal_attributes : {index of ordinal attributes: ordered values}\n",
    "            initialize a labeled set with input dimension and ordinal attributes definition\n",
    "        '''\n",
    "        self.input_dimension = input_dimension\n",
    "        self.nb_examples = 0\n",
    "        self.ordinal_attributes = ordinal_attributes\n",
    "    \n",
    "    def addExample(self,vector,label):\n",
    "        if (self.nb_examples == 0):\n",
    "            self.x = np.array([vector])\n",
    "            self.y = np.array([label])\n",
    "        else:\n",
    "            self.x = np.vstack((self.x, vector))\n",
    "            self.y = np.vstack((self.y, label))\n",
    "        \n",
    "        self.nb_examples = self.nb_examples + 1\n",
    "    \n",
    "    #Renvoie la dimension de l'espace d'entrée\n",
    "    def getInputDimension(self):\n",
    "        return self.input_dimension\n",
    "    \n",
    "    #Renvoie le nombre d'exemples dans le set\n",
    "    def size(self):\n",
    "        return self.nb_examples\n",
    "    \n",
    "    #Renvoie la valeur de x_i\n",
    "    def getX(self, i):\n",
    "        return self.x[i]\n",
    "        \n",
    "    \n",
    "    #Renvoie la valeur de y_i\n",
    "    def getY(self, i):\n",
    "        return(self.y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = dict()\n",
    "val[1] = ['a', 'b', 'c']\n",
    "a_set = LabeledSet(2, val)\n",
    "\n",
    "a_set.addExample([0, 'a'], 1)\n",
    "a_set.addExample([0, 'b'], 1)\n",
    "a_set.addExample([0, 'c'], 1)\n",
    "\n",
    "a_set.x[0][0] < '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = a_set.x.copy()\n",
    "ind = np.transpose(np.array([[i for i in range(a_set.size())]]))\n",
    "values = np.hstack((values, ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0', 'a', '0'],\n",
       "       ['0', 'b', '1'],\n",
       "       ['0', 'c', '2']], dtype='<U21')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v = a_set.getX(1)[1]\n",
    "ind = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-f26934171e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0matt_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordinal_attributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mind_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0matt_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mind_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/laura/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "v = a_set.getX(2)[1]\n",
    "att_values = a_set.ordinal_attributes[1]\n",
    "ind_v = att_values.index(v)\n",
    "att_values.index(values[:,1]) >= ind_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class F_layer:\n",
    "    '''\n",
    "        object-wise local monotonicity measure \n",
    "    '''\n",
    "\n",
    "    def value(self, w_i, labeled_set, esa, esl):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def equal_sets_attribute(self, labeled_set, a_j):    \n",
    "        '''\n",
    "            a_j : index of attribute in labeled_set\n",
    "            labeled_set : labeled set\n",
    "            for each object w in labeled_set, return its equal set generated by a_j  \n",
    "        '''\n",
    "        values = labeled_set.x.copy()\n",
    "        ind = np.transpose(np.array([[i for i in range(labeled_set.size())]]))\n",
    "        values = np.hstack((values, ind))\n",
    "\n",
    "        dominant_sets = dict()\n",
    "        for i in range(0, labeled_set.size()):\n",
    "            v = labeled_set.getX(i)[a_j]\n",
    "            dominant_sets[i] = set(values[values[:,a_j] == v][:,labeled_set.getInputDimension()])\n",
    "\n",
    "        return dominant_sets\n",
    "    \n",
    "    def equal_sets_label(self, labeled_set):    \n",
    "        '''\n",
    "            labeled_set : labeled set\n",
    "            for each object w in labeled_set, return its dominant set generated by its label  \n",
    "        '''\n",
    "        values = labeled_set.y.copy()\n",
    "        ind = np.transpose(np.array([[i for i in range(labeled_set.size())]]))\n",
    "        values = np.hstack((values, ind))\n",
    "\n",
    "        dominant_sets = dict()\n",
    "\n",
    "        for i in range(0, labeled_set.size()):\n",
    "            v = labeled_set.getY(i)\n",
    "            dominant_sets[i] = set(values[values[:,0] == v][:,1])\n",
    "\n",
    "        return dominant_sets\n",
    "    \n",
    "    def dominant_sets_attribute(self, labeled_set, a_j):    \n",
    "        '''\n",
    "            a_j : index of attribute in labeled_set\n",
    "            labeled_set : labeled set\n",
    "            for each object w in labeled_set, return its dominant set generated by a_j  \n",
    "        '''\n",
    "        \n",
    "        values = labeled_set.x.copy()\n",
    "        ind = np.transpose(np.array([[i for i in range(labeled_set.size())]]))\n",
    "        values = np.hstack((values, ind))\n",
    "\n",
    "        dominant_sets = dict()\n",
    "        if not (a_j in labeled_set.ordinal_attributes):\n",
    "            for i in range(0, labeled_set.size()):\n",
    "                v = labeled_set.getX(i)[a_j]\n",
    "                dominant_sets[i] = set(values[values[:,a_j] >= v][:,labeled_set.getInputDimension()])\n",
    "        else:\n",
    "            for i in range(0, labeled_set.size()):\n",
    "                v = labeled_set.getX(i)[a_j]\n",
    "                att_values = labeled_set.ordinal_attributes[a_j]\n",
    "                ind_v = att_values.index(v)\n",
    "                dominant_sets[i] = set(values[att_values.index(values[:,a_j]) >= ind_v][:,labeled_set.getInputDimension()])\n",
    "\n",
    "        return dominant_sets\n",
    "\n",
    "    def dominant_sets_label(self, labeled_set):\n",
    "        '''\n",
    "            labeled_set : labeled set\n",
    "            for each object w in labeled_set, return its dominant set generated by its label  \n",
    "        '''\n",
    "        values = labeled_set.y.copy()\n",
    "        ind = np.transpose(np.array([[i for i in range(labeled_set.size())]]))\n",
    "        values = np.hstack((values, ind))\n",
    "\n",
    "        dominant_sets = dict()\n",
    "\n",
    "        for i in range(0, labeled_set.size()):\n",
    "            v = labeled_set.getY(i)\n",
    "            dominant_sets[i] = set(values[values[:,0] >= v][:,1])\n",
    "\n",
    "        return dominant_sets\n",
    "    \n",
    "class Ds(F_layer):\n",
    "    def value(self, w_i, labeled_set, esa, esl):\n",
    "        '''\n",
    "            labeled_set : labeled set\n",
    "            w_i : index of object in labeled_set\n",
    "            return ds value of w_i, a_j\n",
    "        '''\n",
    "        esa_i = esa[w_i]\n",
    "        esl_i = esl[w_i]\n",
    "        intersection = esa_i.intersection(esl_i)\n",
    "        \n",
    "        return len(intersection) * 1.0 / len(esa_i)    \n",
    "\n",
    "class Dsr(F_layer):\n",
    "    \n",
    "    def value(self, w_i, labeled_set, dsa, dsl):\n",
    "        '''\n",
    "            labeled_set : labeled set\n",
    "            w_i : index of object in labeled_set\n",
    "            return dsr value of w_i, a_j\n",
    "        '''\n",
    "        dsa_i = dsa[w_i]\n",
    "        dsl_i = dsl[w_i]\n",
    "        intersection = dsa_i.intersection(dsl_i)\n",
    "        \n",
    "        return len(intersection) * 1.0 / len(dsa_i)   \n",
    "    \n",
    "class Minds(F_layer):\n",
    "    \n",
    "    def value(self, w_i, labeled_set, esa, esl):\n",
    "        '''\n",
    "            labeled_set : labeled set\n",
    "            w_i : index of object in labeled_set\n",
    "            return minds value of w_i, a_j\n",
    "        '''\n",
    "        n = labeled_set.size()\n",
    "        intersections_lengths = []\n",
    "        equal_set = esa[w_i]\n",
    "        \n",
    "        for w_h in equal_set:\n",
    "            intersections_lengths.append(len(esa[w_h].intersection(esl[w_h])))\n",
    "    \n",
    "        return min(intersections_lengths) * 1.0 / len(equal_set)       \n",
    "    \n",
    "class Mindsr(F_layer):  \n",
    "    def value(self, w_i, labeled_set, dsa, dsl):\n",
    "        '''\n",
    "            labeled_set : labeled set\n",
    "            w_i : index of object in labeled_set\n",
    "            return mindsr value of w_i, a_j\n",
    "        '''\n",
    "        n = labeled_set.size()\n",
    "        intersections_lengths = []\n",
    "        dominant_set = dsa[w_i]\n",
    "        \n",
    "        for w_h in dominant_set:\n",
    "            intersections_lengths.append(len(dsa[w_h].intersection(dsl[w_h])))\n",
    "    \n",
    "        return min(intersections_lengths) * 1.0 / len(dominant_set)    \n",
    "    \n",
    "class Maxdsr(F_layer):\n",
    "    def value(self, w_i, labeled_set, dsa, dsl):\n",
    "        '''\n",
    "            w_i : index of object in labeled_set\n",
    "            return maxdsr value of w_i, a_j\n",
    "        '''\n",
    "        n = labeled_set.size()\n",
    "        intersections_lengths = []\n",
    "\n",
    "        dominant_set = dsa[w_i]\n",
    "        \n",
    "        for w_h in dominant_set:\n",
    "            intersections_lengths.append(len(dsa[w_h].intersection(dsl[w_h])))\n",
    "    \n",
    "    \n",
    "        return max(intersections_lengths) * 1.0 / len(dominant_set)    \n",
    "    \n",
    "class Maxds(F_layer):\n",
    "\n",
    "    def value(self, w_i, labeled_set, esa, esl):\n",
    "        '''\n",
    "            w_i : index of object in labeled_set\n",
    "            return maxds value of w_i, a_j\n",
    "        '''\n",
    "        n = labeled_set.size()\n",
    "        intersections_lengths = []\n",
    "\n",
    "        equal_set = esa[w_i]\n",
    "        \n",
    "        for w_h in equal_set:\n",
    "            intersections_lengths.append(len(esa[w_h].intersection(esl[w_h])))\n",
    "    \n",
    "    \n",
    "        return max(intersections_lengths) * 1.0 / len(equal_set)\n",
    "\n",
    "class Avgdsr(F_layer):\n",
    "    def value(self, w_i, labeled_set, dsa, dsl):\n",
    "        '''\n",
    "            labeled_set : labeled set\n",
    "            w_i : index of object in labeled_set\n",
    "            return avgdsr value of w_i, a_j\n",
    "        '''\n",
    "        n = labeled_set.size()\n",
    "        intersections_lengths = []\n",
    "\n",
    "        dominant_set = dsa[w_i]\n",
    "        \n",
    "        for w_h in dominant_set:\n",
    "            intersections_lengths.append(len(dsa[w_h].intersection(dsl[w_h])))\n",
    "            \n",
    "        return (1.0/len(dominant_set) * np.sum(intersections_lengths)) * 1.0 / len(dominant_set)    \n",
    "\n",
    "class Avgds(F_layer):\n",
    "    def value(self, w_i, labeled_set, esa, esl):\n",
    "        '''\n",
    "            labeled_set : labeled set\n",
    "            w_i : index of object in labeled_set\n",
    "            return avgds value of w_i, a_j\n",
    "        '''\n",
    "        n = labeled_set.size()\n",
    "        intersections_lengths = []\n",
    "\n",
    "        equal_set = esa[w_i]\n",
    "        \n",
    "        for w_h in equal_set:\n",
    "            intersections_lengths.append(len(esa[w_h].intersection(esl[w_h])))\n",
    "            \n",
    "        return (1.0/len(equal_set) * np.sum(intersections_lengths)) * 1.0 / len(equal_set)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class G_layer:\n",
    "    '''\n",
    "        object-wise local non-monotonicity measure\n",
    "    '''\n",
    "        \n",
    "    def value(self, f_value):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class Log(G_layer):    \n",
    "    def value(self, f_value):\n",
    "        '''\n",
    "            f_value : value computed by f_layer\n",
    "            return -log_2(f_value)\n",
    "        '''\n",
    "        return -log(f_value, 2) \n",
    "    \n",
    "class One_minus(G_layer):    \n",
    "    def value(self, f_value):\n",
    "        '''\n",
    "            f_value : value computed by f_layer\n",
    "            return 1 - f_value\n",
    "        '''\n",
    "        return 1 - f_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class H_layer:\n",
    "    '''\n",
    "        aggregated local non-monotonicity measure\n",
    "    '''\n",
    "        \n",
    "    def value(self, g_values, labeled_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class Sum(H_layer):    \n",
    "    def value(self, g_values, labeled_set):\n",
    "        '''\n",
    "            return (1/labeled_set.size()) * sum(g_values)\n",
    "        '''\n",
    "        return (1.0/labeled_set.size()) * np.sum(g_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gdm:\n",
    "    '''\n",
    "        Generic rank discrimination measure\n",
    "    '''\n",
    "    def __init__(self, h, g, f):\n",
    "        '''\n",
    "            h : object-wise local monotonicity measure \n",
    "            g : object-wise local non-monotonicity measure \n",
    "            f : aggregated local non-monotonicity measure\n",
    "            labeled_set : labeled set\n",
    "        '''\n",
    "        self.h = h \n",
    "        self.g = g\n",
    "        self.f = f\n",
    "    \n",
    "    def value(self, labeled_set, a_j):\n",
    "        g_f = []\n",
    "\n",
    "        if (isinstance(self.f, Dsr)):\n",
    "            sa = self.f.dominant_sets_attribute(labeled_set, a_j)\n",
    "            sl = self.f.dominant_sets_label(labeled_set)\n",
    "        else:\n",
    "            sa = self.f.equal_sets_attribute(labeled_set, a_j)\n",
    "            sl = self.f.equal_sets_label(labeled_set)\n",
    "        \n",
    "        for i in range(0, labeled_set.size()):\n",
    "            g_f.append(self.g.value(self.f.value(i, labeled_set, sa, sl)))\n",
    "        \n",
    "        return self.h.value(g_f, labeled_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discretize(H, labeled_set, a_j):\n",
    "    '''\n",
    "        H : discrimation measure\n",
    "        labeled_set : labeled set\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    n = labeled_set.size()\n",
    "    ind = np.argsort(labeled_set.x,axis=0)[:,a_j] # sort values \n",
    "    \n",
    "    binary_set = LabeledSet(labeled_set.getInputDimension())\n",
    "    binary_set.nb_examples = labeled_set.size()\n",
    "    binary_set.x = labeled_set.x.copy()\n",
    "    binary_set.x[:,a_j] = np.ones(labeled_set.size())\n",
    "    binary_set.y = labeled_set.y\n",
    "    \n",
    "    thresholds = []\n",
    "    H_values = []\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        current = labeled_set.getX(ind[i])[a_j]\n",
    "        current_label = labeled_set.getY(ind[i])\n",
    "        lookahead = labeled_set.getX(ind[i+1])[a_j]\n",
    "        lookahead_label = labeled_set.getY(ind[i+1])\n",
    "        binary_set.x[ind[i]][a_j] = 0\n",
    "        \n",
    "        if current == lookahead or current_label == lookahead_label:\n",
    "            continue\n",
    "\n",
    "        thresholds.append((current + lookahead) / 2.0)\n",
    "        H_values.append(H.value(binary_set, a_j))\n",
    "        \n",
    "    min_entropy = min(H_values)\n",
    "    min_threshold = thresholds[np.argmin(H_values)]\n",
    "    \n",
    "    return (min_threshold, min_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def majority_class(labeled_set, labels):\n",
    "    classes_size = []\n",
    "    \n",
    "    for label in labels:\n",
    "        classes_sizes.append(len(labeledSet.x[np.where(labeledSet.y == label),:][0]))\n",
    "\n",
    "    return labels[np.argmax(np.array(classes_size))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide(Lset, att, threshold):\n",
    "    '''\n",
    "        Lset : labeled_set\n",
    "        att : index of attribute to divide\n",
    "        threshold : threshold value\n",
    "    '''\n",
    "    E1 = LabeledSet(Lset.getInputDimension())\n",
    "    E2 = LabeledSet(Lset.getInputDimension())\n",
    "    \n",
    "    # Separate data according to threshold\n",
    "    for i in range(Lset.size()):\n",
    "        if Lset.getX(i)[att] <= seuil:\n",
    "            E1.addExample(Lset.getX(i), Lset.getY(i))\n",
    "        else:\n",
    "            E2.addExample(Lset.getX(i), Lset.getY(i))\n",
    "    \n",
    "    return E1, E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenericTree:\n",
    "    '''\n",
    "        Generic tree\n",
    "        deal with both numeric and ordinal attributes\n",
    "        deal with multi-class classification\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.attribute = None\n",
    "        self.children = None\n",
    "        self.label = None\n",
    "        \n",
    "        # binary tree\n",
    "        self.threshold = None\n",
    "        self.inf = None\n",
    "        self.sup = None\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        \"\"\" \n",
    "            return True if tree is a leaf\n",
    "        \"\"\"\n",
    "        return self.attribute == None\n",
    "    \n",
    "    def add_children(self,children,att):\n",
    "        \"\"\" \n",
    "            child: dictionnary key=category, value=tree\n",
    "            att: index of attribute\n",
    "        \"\"\"\n",
    "        self.attribut = att\n",
    "        self.fils = fils\n",
    "    \n",
    "    def add_children_binary(self, inf, sup, att, threshold):\n",
    "        \"\"\"\n",
    "            inf, sup : trees\n",
    "            att : index of attribute\n",
    "            threshold : threshold value\n",
    "        \"\"\"\n",
    "        self.attribute = att\n",
    "        self.threshold = threshold\n",
    "        self.inf = inf\n",
    "        self.sup = sup\n",
    "    \n",
    "    def addLeaf(self,label):\n",
    "        \"\"\" \n",
    "            add leaf corresponding to label\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "        \n",
    "    def classify(self,example):\n",
    "        \"\"\" \n",
    "            example : numpy array in labeled set\n",
    "            classify example\n",
    "        \"\"\"\n",
    "        if self.isLeaf():\n",
    "            return self.label\n",
    "        else:\n",
    "            if threshold is None:\n",
    "                for c,f in self.children.items():\n",
    "                    if c == example[self.attribute]:\n",
    "                        return f.classify(example)\n",
    "            else:\n",
    "                if example[self.attribute] <= self.threshold:\n",
    "                    return self.inf.classify(example)\n",
    "                return self.sup.classify(example)\n",
    "                \n",
    "    def to_graph(self, g, prefix='A'):\n",
    "        \"\"\" \n",
    "            build a representation of the tree\n",
    "        \"\"\"\n",
    "        if self.isLeaf():\n",
    "            g.node(prefix,str(self.label),shape='box')\n",
    "        else:\n",
    "            g.node(prefix, str(self.attribute))\n",
    "            \n",
    "            if threshold is None: \n",
    "                for c, f in self.fils.items():\n",
    "                    f.to_graph(g,prefixe+c)\n",
    "                    g.edge(prefixe,prefixe+c, c)\n",
    "            else:\n",
    "                g.node(prefix, str(self.attribute))\n",
    "                self.inf.to_graph(g,prefixe+\"l\")\n",
    "                self.sup.to_graph(g,prefixe+\"r\")\n",
    "                g.edge(prefix,prefixe+\"l\", '<='+ str(self.threshold))\n",
    "                g.edge(prefix,prefixe+\"r\", '>'+ str(self.threshold))\n",
    "        return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_DT(labeled_set, H, H_stop, measureThreshold, maxDepth, percMinSize, labels, current_depth):\n",
    "    '''\n",
    "        labeled_set : labeled set\n",
    "        H : rank discrimination measure used for discretization\n",
    "        H_stop : discrimination measure (shannon, gini ...)\n",
    "        measure_threshold : lower bound for H_stop\n",
    "        max_depth : maximum length of a path from the root to a leaf node\n",
    "        percMinSize : minimum size of the current object set labeled_set\n",
    "    '''\n",
    "    \n",
    "    min_entropy = 1.1\n",
    "    m = labeled_set.getInputDimension()\n",
    "    threshold = None\n",
    "    attribute = None\n",
    "    categories = []\n",
    "    \n",
    "    h_values = []\n",
    "    thresholds = []\n",
    "    \n",
    "    for a_j in range(m):\n",
    "        # numeric attribute\n",
    "        if isistance(labeled_set.getX(0)[a_j], numbers.Real):\n",
    "            threshold, h = discretize(H, labeled_set, a_j)\n",
    "        else:\n",
    "            n = labeled_set.size()\n",
    "            cat = []\n",
    "            distribution = \n",
    "        \n",
    "        if isinstance(labeled_set.getX(0)[attribute], numbers.Real):\n",
    "            inf, sup = divide(labeled_set, attribute, threshold)\n",
    "            tree = BinaryTree()\n",
    "            \n",
    "            if (inf.size() < percMinSize) or (sup.size() < percMinSize):\n",
    "                if sup.size() < percMinSize:\n",
    "                    tree.addLeaf(majority_class(Linf, labels, None))\n",
    "                    return tree\n",
    "                else:\n",
    "                    tree.addLeaf(majority_class(Lsup, labels, None))\n",
    "                    return tree\n",
    "            if (maxDepth > current_depth + 1):\n",
    "                tree.addLeaf(majority_class(Linf, labels, \"left\"))\n",
    "                tree.addLeaf(majority_class(Lsup, labels, \"right\"))\n",
    "                return tree\n",
    "        else:\n",
    "            k = len(categories)\n",
    "            E = divide_ordinal(labeled_set, attribute, categories)\n",
    "            tree = GenericTree()\n",
    "            fils = dict()\n",
    "            for i in range(k):\n",
    "                fils[categories[i]] = construit_AD(E[i], epsilon, labels)\n",
    "            AC.ajoute_fils(fils, attribut)\n",
    "            \n",
    "            return AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz as gv\n",
    "import numbers\n",
    "\n",
    "########## LABELEDSET ##########\n",
    "\n",
    "class LabeledSet:   \n",
    "    def __init__(self, input_dimension):\n",
    "        self.input_dimension = input_dimension\n",
    "        self.nb_examples = 0\n",
    "    \n",
    "    def addExample(self,vector,label):\n",
    "        if (self.nb_examples == 0):\n",
    "            self.x = np.array([vector])\n",
    "            self.y = np.array([label])\n",
    "        else:\n",
    "            self.x = np.vstack((self.x, vector))\n",
    "            self.y = np.vstack((self.y, label))\n",
    "        \n",
    "        self.nb_examples = self.nb_examples + 1\n",
    "    \n",
    "    #Renvoie la dimension de l'espace d'entrée\n",
    "    def getInputDimension(self):\n",
    "        return self.input_dimension\n",
    "    \n",
    "    #Renvoie le nombre d'exemples dans le set\n",
    "    def size(self):\n",
    "        return self.nb_examples\n",
    "    \n",
    "    #Renvoie la valeur de x_i\n",
    "    def getX(self, i):\n",
    "        return self.x[i]\n",
    "        \n",
    "    \n",
    "    #Renvoie la valeur de y_i\n",
    "    def getY(self, i):\n",
    "        return(self.y[i])\n",
    "    \n",
    "        \n",
    "##################################\n",
    "\n",
    "########## CLASSIFIER ##########\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self,input_dimension):\n",
    "        \"\"\" Constructeur \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    \n",
    "    # Permet de calculer la prediction sur x => renvoie un score\n",
    "    def predict(self,x):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    \n",
    "    # Permet d'entrainer le modele sur un ensemble de données étiquetés\n",
    "    def train(self,labeledSet):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    # Permet de calculer le taux de bonne classification\n",
    "    def accuracy(self,set):\n",
    "        nb_ok=0\n",
    "        for i in range(set.size()):\n",
    "            score = self.predict(set.getX(i))\n",
    "            if (score*set.getY(i)>0):\n",
    "                nb_ok = nb_ok+1\n",
    "        acc = nb_ok/(set.size() * 1.0)\n",
    "        return acc    \n",
    "    \n",
    "def plot_frontiere(set,classifier,step=10):\n",
    "    \"\"\" LabeledSet * Classifier * int -> NoneType\n",
    "        Remarque: le 3e argument est optionnel et donne la \"résolution\" du tracé\n",
    "        affiche la frontière de décision associée au classifieur\n",
    "    \"\"\"\n",
    "    mmax=set.x.max(0)\n",
    "    mmin=set.x.min(0)\n",
    "    x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],step),np.linspace(mmin[1],mmax[1],step))\n",
    "    grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
    "    \n",
    "    # calcul de la prediction pour chaque point de la grille\n",
    "    res=np.array([classifier.predict(grid[i,:]) for i in range(len(grid)) ])\n",
    "    res=res.reshape(x1grid.shape)\n",
    "    # tracer des frontieres\n",
    "    plt.contourf(x1grid,x2grid,res,colors=[\"red\",\"cyan\"],levels=[-1000,0,1000],linewidth=2)\n",
    "\n",
    "######################################################    \n",
    "    \n",
    "########### Entropy ###########  \n",
    "\n",
    "def majority_class(labeled_set, labels):\n",
    "    classes_size = []\n",
    "    \n",
    "    for label in labels:\n",
    "        classes_sizes.append(len(labeledSet.x[np.where(labeledSet.y == label),:][0]))\n",
    "\n",
    "    return labels[np.argmax(np.array(classes_size))]\n",
    "\n",
    "################# TREE REPRESENTATION ###############\n",
    "\n",
    "class GenericTree:\n",
    "    '''\n",
    "        Generic tree\n",
    "        deal with both numeric and ordinal attributes\n",
    "        deal with multi-class classification\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.attribute = None\n",
    "        self.children = None\n",
    "        self.label = None\n",
    "        \n",
    "        # binary tree\n",
    "        self.threshold = None\n",
    "        self.inf = None\n",
    "        self.sup = None\n",
    "        \n",
    "    def isLeaf(self):\n",
    "        \"\"\" \n",
    "            return True if tree is a leaf\n",
    "        \"\"\"\n",
    "        return self.attribute == None\n",
    "    \n",
    "    def add_children(self,children,att):\n",
    "        \"\"\" \n",
    "            child: dictionnary key=category, value=tree\n",
    "            att: index of attribute\n",
    "        \"\"\"\n",
    "        self.attribut = att\n",
    "        self.fils = fils\n",
    "    \n",
    "    def add_children_binary(self, inf, sup, att, threshold):\n",
    "        \"\"\"\n",
    "            inf, sup : trees\n",
    "            att : index of attribute\n",
    "            threshold : threshold value\n",
    "        \"\"\"\n",
    "        self.attribute = att\n",
    "        self.threshold = threshold\n",
    "        self.inf = inf\n",
    "        self.sup = sup\n",
    "    \n",
    "    def addLeaf(self,label):\n",
    "        \"\"\" \n",
    "            add leaf corresponding to label\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "        \n",
    "    def classify(self,example):\n",
    "        \"\"\" \n",
    "            example : numpy array in labeled set\n",
    "            classify example\n",
    "        \"\"\"\n",
    "        if self.isLeaf():\n",
    "            return self.label\n",
    "        else:\n",
    "            if threshold is None:\n",
    "                for c,f in self.children.items():\n",
    "                    if c == example[self.attribute]:\n",
    "                        return f.classify(example)\n",
    "            else:\n",
    "                if example[self.attribute] <= self.threshold:\n",
    "                    return self.inf.classify(example)\n",
    "                return self.sup.classify(example)\n",
    "                \n",
    "    def to_graph(self, g, prefix='A'):\n",
    "        \"\"\" \n",
    "            build a representation of the tree\n",
    "        \"\"\"\n",
    "        if self.isLeaf():\n",
    "            g.node(prefix,str(self.label),shape='box')\n",
    "        else:\n",
    "            g.node(prefix, str(self.attribute))\n",
    "            \n",
    "            if threshold is None: \n",
    "                for c, f in self.fils.items():\n",
    "                    f.to_graph(g,prefixe+c)\n",
    "                    g.edge(prefixe,prefixe+c, c)\n",
    "            else:\n",
    "                g.node(prefix, str(self.attribute))\n",
    "                self.inf.to_graph(g,prefixe+\"l\")\n",
    "                self.sup.to_graph(g,prefixe+\"r\")\n",
    "                g.edge(prefix,prefixe+\"l\", '<='+ str(self.threshold))\n",
    "                g.edge(prefix,prefixe+\"r\", '>'+ str(self.threshold))\n",
    "        return g \n",
    "\n",
    "def build_DT(labeled_set, H, measureThreshold, maxDepth, percMinSize, labels, current_depth)\n",
    "    '''\n",
    "    if current_depth > maxDepth or percMinSize > labeled_set.size():\n",
    "        leaf = GenericTree()\n",
    "        leaf.addLeaf(majority_class(labeled_set, labels))\n",
    "        return leaf\n",
    "    \n",
    "    entro = entropy(labeled_set, labels) \n",
    "    m = labeled_set.getInputDimension()\n",
    "    \n",
    "    if entro <= epsilon:\n",
    "        feuille = ArbreBinaire()\n",
    "        feuille.ajoute_feuille(classe_majoritaire(Lset, labels))\n",
    "        return feuille\n",
    "    else:\n",
    "    '''\n",
    "    \n",
    "    min_entropy = 1.1\n",
    "    m = labeled_set.getInputDimension()\n",
    "    threshold = None\n",
    "    attribute = None\n",
    "    categories = []\n",
    "    \n",
    "    for attr in range(m):\n",
    "        if isistance(labeled_set.getX(0)[attr], numbers.Real):\n",
    "            s, entro = discretisation(labeled_set, attr, labels)\n",
    "            if (min_entropy > entro):\n",
    "                min_entropy = entro\n",
    "                threshold = s\n",
    "                attribute = attr\n",
    "        else:\n",
    "            n = labeled_set.size()\n",
    "            cat = []\n",
    "            distribution \n",
    "        \n",
    "        if isinstance(labeled_set.getX(0)[attribute], numbers.Real):\n",
    "            inf, sup = divide(labeled_set, attribute, threshold)\n",
    "            tree = BinaryTree()\n",
    "            \n",
    "            if (inf.size() < percMinSize) or (sup.size() < percMinSize):\n",
    "                if sup.size() < percMinSize:\n",
    "                    tree.addLeaf(majority_class(Linf, labels, None))\n",
    "                    return tree\n",
    "                else:\n",
    "                    tree.addLeaf(majority_class(Lsup, labels, None))\n",
    "                    return tree\n",
    "            if (maxDepth > current_depth + 1):\n",
    "                tree.addLeaf(majority_class(Linf, labels, \"left\"))\n",
    "                tree.addLeaf(majority_class(Lsup, labels, \"right\"))\n",
    "                return tree\n",
    "        else:\n",
    "            k = len(categories)\n",
    "            E = divide_ordinal(labeled_set, attribute, categories)\n",
    "            tree = GenericTree()\n",
    "            fils = dict()\n",
    "            for i in range(k):\n",
    "                fils[categories[i]] = construit_AD(E[i], epsilon, labels)\n",
    "            AC.ajoute_fils(fils, attribut)\n",
    "            \n",
    "            return AC\n",
    "        \n",
    "#############################################################\n",
    "\n",
    "########################## RDMT #############################\n",
    "    \n",
    "class RDMT(Classifier):\n",
    "    '''\n",
    "        Rank discrimination measure tree \n",
    "    '''\n",
    "    def __init__(self, H, measureThreshold, maxDepth, percMinSize, labels):\n",
    "        '''\n",
    "            H : discrimination measure to minimize for splitting\n",
    "            measureThreshold : lower bound for the discrimination measure H\n",
    "            maxDepth : maximum length of a path from the root to a leaf node\n",
    "            percMinSize : minimum size of the current object set \n",
    "            labels : set of classes\n",
    "        '''\n",
    "        self.H = H\n",
    "        self.measureThreshold = measureThreshold\n",
    "        self.maxDepth = maxDepth\n",
    "        self.percMinSize = percMinSize\n",
    "        self.labels = labels\n",
    "        self.root = None\n",
    "        \n",
    "    def predict(self,x):\n",
    "        '''\n",
    "            classify x using RDMT\n",
    "            return prediction\n",
    "        '''\n",
    "        label = self.root.classify(x)\n",
    "        return label\n",
    "    \n",
    "    def train(self,set):\n",
    "        '''\n",
    "            set : training set\n",
    "            builds RDMT using set\n",
    "        '''\n",
    "        self.set = set\n",
    "        self.root = build_DT(set,self.H, self.measureThreshold, self.maxDepth, self.percMinSize, self.labels, 0)\n",
    "    \n",
    "    def plot(self):\n",
    "        '''\n",
    "            display tree\n",
    "        '''\n",
    "        gtree = gv.Digraph(format='png')\n",
    "        return self.root.to_graph(gtree)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
