{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from arbres import *\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = LabeledSet(2)\n",
    "\n",
    "for i in range(0, 3):\n",
    "    training_set.addExample([random.randint(0,2),random.randint(0,10)],1)\n",
    "for i in range(0, 3):\n",
    "    training_set.addExample([random.randint(3, 5), random.randint(0, 10)], 2)\n",
    "for i in range(0, 4):\n",
    "    training_set.addExample([random.randint(6, 10), random.randint(0,10)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 4, 4, 5, 7, 8, 8, 10]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(training_set.x[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0],\n",
       "       [ 0,  2],\n",
       "       [ 0,  2],\n",
       "       [ 5,  2],\n",
       "       [ 4,  5],\n",
       "       [ 4,  8],\n",
       "       [ 8,  9],\n",
       "       [ 8,  6],\n",
       "       [10,  0],\n",
       "       [ 7, 10]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0, 3, 4, 5, 6, 7, 8, 9}, 1: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 2: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 3: {3, 6, 7, 8, 9}, 4: {3, 4, 5, 6, 7, 8, 9}, 5: {3, 4, 5, 6, 7, 8, 9}, 6: {8, 6, 7}, 7: {8, 6, 7}, 8: {8}, 9: {8, 9, 6, 7}}\n",
      "{0: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 1: {1, 2, 3, 4, 5, 6, 7, 9}, 2: {1, 2, 3, 4, 5, 6, 7, 9}, 3: {1, 2, 3, 4, 5, 6, 7, 9}, 4: {4, 5, 6, 7, 9}, 5: {9, 5, 6}, 6: {9, 6}, 7: {9, 5, 6, 7}, 8: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 9: {9}}\n",
      "{0: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 1: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 2: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}, 3: {3, 4, 5, 6, 7, 8, 9}, 4: {3, 4, 5, 6, 7, 8, 9}, 5: {3, 4, 5, 6, 7, 8, 9}, 6: {8, 9, 6, 7}, 7: {8, 9, 6, 7}, 8: {8, 9, 6, 7}, 9: {8, 9, 6, 7}}\n"
     ]
    }
   ],
   "source": [
    "def dominant_sets_attribute(a_j, labeled_set):    \n",
    "    dominant_sets = dict()\n",
    "    for i in range(0, labeled_set.size()):\n",
    "        dominant_sets[i] = set()\n",
    "        for k in range(0, labeled_set.size()):\n",
    "            if labeled_set.getX(k)[a_j] >= labeled_set.getX(i)[a_j]:\n",
    "                dominant_sets[i].add(k)\n",
    "                \n",
    "    return dominant_sets\n",
    "\n",
    "def dominant_sets_label(labeled_set):\n",
    "    dominant_sets = dict()\n",
    "    for i in range(0, labeled_set.size()):\n",
    "        dominant_sets[i] = set()\n",
    "        for k in range(0, labeled_set.size()):\n",
    "            if labeled_set.getY(k) >= labeled_set.getY(i):\n",
    "                dominant_sets[i].add(k)\n",
    "                \n",
    "    return dominant_sets\n",
    "    \n",
    "print(dominant_sets_attribute(0, training_set))\n",
    "print(dominant_sets_attribute(1, training_set))\n",
    "print(dominant_sets_label(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dsr(w_i, a_j, labeled_set):\n",
    "    dominant_set_attr = dominant_sets_attribute(a_j, labeled_set)[w_i]\n",
    "    dominant_set_label = dominant_sets_label(labeled_set)[w_i]\n",
    "    intersection = dominant_set_attr.intersection(dominant_set_label)\n",
    "    \n",
    "    return len(intersection) * 1.0 / len(dominant_set_attr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(dsr(i, 0, training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3, 4, 5, 6, 7, 8, 9}\n",
      "{3, 4, 5, 6, 7, 9}\n",
      "{1, 2, 3, 4, 5, 6, 7, 9}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsr(3, 1, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.75\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.75\n",
      "0.4\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(dsr(i, 1, training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rdm(h, g, f, a_j, labeled_set):\n",
    "    g_f = []\n",
    "    \n",
    "    for i in range(0, labeled_set.size()):         \n",
    "        g_f.append(g(f(i, a_j, labeled_set)))\n",
    "        \n",
    "    return reduce(h, g_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.215200309344505\n",
      "0.11\n"
     ]
    }
   ],
   "source": [
    "# rsdm\n",
    "print(rdm(lambda x, y:(x+y), lambda x:(1.0/training_set.size())*-log(x,2), dsr, 1, training_set))\n",
    "# rgdm \n",
    "print(rdm(lambda x, y:(x+y), lambda x:(1.0/training_set.size())*(1-x), dsr, 1, training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([item for sublist in training_set.y.tolist() for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot2DSet(labeled_set):\n",
    "    \"\"\" LabeledSet -> NoneType\n",
    "        Hypothèse: set est de dimension 2\n",
    "        affiche une représentation graphique du LabeledSet\n",
    "        remarque: l'ordre des labels dans set peut être quelconque\n",
    "    \"\"\"\n",
    "    labels = list(set([item for sublist in labeled_set.y.tolist() for item in sublist]))\n",
    "    markers = ['o', 'x', '*', 'v']\n",
    "    S = []\n",
    "    for label in labels:\n",
    "        S.append(labeled_set.x[np.where(labeled_set.y == label),:][0])\n",
    "    for i in range(len(labels)):\n",
    "        plt.scatter(S[i][:,0],S[i][:,1],marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 0],\n",
      "       [0, 2],\n",
      "       [0, 2]]), array([[5, 2],\n",
      "       [4, 5],\n",
      "       [4, 8]]), array([[ 8,  9],\n",
      "       [ 8,  6],\n",
      "       [10,  0],\n",
      "       [ 7, 10]])]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAED1JREFUeJzt3W+IXHe9x/HPJ/9YW7exklViUu5WKJpQKJWJqaaItj5I\nNRifiBXWliIEgtYqwtLcBwb64EYW8Q/FDYa2sTClRWLBEi7RUiOlRUImbchts/4pbWyj0YxI06Xc\nkJR874OZSc7OTbK7c86Zs/Pb9wvC7hlm93xPk77zy2935zgiBAAYfEuqHgAAUAyCDgCJIOgAkAiC\nDgCJIOgAkAiCDgCJIOgAkAiCDgCJIOgAkIhl/TzZqlWrYnR0tJ+nBICBd+TIkX9FxMhsz+tr0EdH\nR9VoNPp5SgAYeLb/OpfnseUCAIkg6ACQCIIOAIkg6ACQCIIOAIkg6ACQCIIOAImYNei2H7N92vYr\nmcc+aPtZ239pv72+3DEBFKH7lpPcgjItc1mh/0LS5q7HHpT0XETcJOm59jGABWzy6KQmDk9cjHhE\naOLwhCaPTlY8GYoya9Aj4nlJ/+56eKukx9vvPy7pywXPBaBAEaHpc9OqT9UvRn3i8ITqU3VNn5tm\npZ6IXn/0/8MRcUqSIuKU7Q8VOBOAgtnW+IZxSVJ9qq76VF2SNLZuTOMbxmW7yvFQkNK/KGp7m+2G\n7Uaz2Sz7dACuIBv1DmKell6D/k/bqyWp/fb0lZ4YEXsiohYRtZGRWV8sDEBJOtssWdk9dQy+XoP+\njKR72+/fK+nXxYwDoAzZPfOxdWM6ds8xja0bm7GnjsE36x667SclfVbSKtsnJe2U9ANJv7T9DUlv\nSvpKmUMCyMe2hlcMz9gz72y/DK8YZtslEe7n38y1Wi14PXSgOhExI97dx1iYbB+JiNpsz+MnRYFF\npDvexDwtBB0AEkHQASARBB0AEkHQASARBB0AEkHQASARBB0AEkHQASARBB0AEkHQAZSOW9/1B0EH\nUCpufdc/BB1Aabj1XX/1egs6AJgVt77rL1boAErFre/6h6ADKBW3vusfgg6gNNz6rr/YQwdQGm59\n11/cgg5A6bj1XT7cgg7AgsGt7/qDoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSC\noANAIgg6qtf98hO8YBPQk1xBt/1d26/afsX2k7aHihoMi8TBXdKBHZciHtE6Prir2rmAAdRz0G2v\nkfRtSbWIuFnSUkl3FzUYFoEI6ewZ6dDuS1E/sKN1fPYMK3VgnvK+fO4ySe+zfV7SNZL+nn8kLBq2\ntLm9Ej+0u/VLkjZubz3OCzgB89LzCj0i/ibph5LelHRK0pmI+G3382xvs92w3Wg2m71PijRlo95B\nzIGe5NlyuV7SVkk3SvqIpGttj3U/LyL2REQtImojIyO9T4o0dbZZsrJ76gDmLM8XRT8v6Y2IaEbE\neUlPS/p0MWNhUcjumW/cLu18u/U2u6cOYM7y7KG/Kek229dI+l9Jd0ridkSYO1saWjlzz7yz/TK0\nkm0XYJ56DnpEHLK9T9JLkt6T9LKkPUUNhkXic+2VeCfenagTc2Decn2XS0TslLSzoFmwWHXHm5gD\nPeEnRQEgEQQdABJB0AEgEQQdABJB0AEgEQQdABJB0AEgEQQdABJB0AEgEQQdABJB0AEgEQQdABJB\n0AEgEQQdABJB0AEgEQQdABJB0AEgEQQdABJB0AEgEQQdABJB0AEgEQQdABJB0AEgEQQdABJB0AEg\nEQQdABJB0AEgEQQdABJB0AEgEbmCbvsDtvfZ/qPtKdufKmowAOmIiKseoxh5V+g/lXQgIj4u6RZJ\nU/lHApCSyaOTmjg8cTHiEaGJwxOaPDpZ8WTp6Tnotq+T9BlJj0pSRJyLiLeLGgzA4IsITZ+bVn2q\nfjHqE4cnVJ+qa/rcNCv1gi3L8bEfldSUtNf2LZKOSHogIt4tZDIAA8+2xjeMS5LqU3XVp+qSpLF1\nYxrfMC7bVY6XnDxbLsskfULS7oi4VdK7kh7sfpLtbbYbthvNZjPH6QAMomzUO4h5OfIE/aSkkxFx\nqH28T63AzxAReyKiFhG1kZGRHKcDMIg62yxZ2T11FKfnoEfEPyS9Zftj7YfulHS8kKkAJCG7Zz62\nbkzH7jmmsXVjM/bUUZw8e+iSdL+kJ2yvkPS6pPvyjwQgFbY1vGJ4xp55Z/tleMUw2y4Fcz//hqzV\natFoNPp2PgALQ0TMiHf3Ma7O9pGIqM32PH5SFEDpuuNNzMtB0AEgEQQdABJB0AEgEQQdABJB0AEg\nEQQdABJB0AEgEQQdABJB0AEgEQQd1et++QlesAnoCUFHtQ7ukg7suBTxiNbxwV3VzgUMIIKO6kRI\nZ89Ih3ZfivqBHa3js2dYqQPzlPflc4He2dLm9kr80O7WL0nauL31OC/gBMwLK3RUKxv1DmIO9ISg\no1qdbZas7J46gDkj6KhOds9843Zp59utt9k9dQBzxh46qmNLQytn7pl3tl+GVrLtAswTQUe1Ptde\niXfi3Yk6MQfmjS0XVK873sQc6AlBB4BEEHQASARBB4BEEHQASARBB4BEEHQASARBB4BEEHQASARB\nB4BEEHQASETuoNteavtl2/uLGAgA0JsiVugPSJoq4PMAAHLIFXTbayV9UdIjxYwDAOhV3hX6TySN\nS7pwpSfY3ma7YbvRbDZzng4AcCU9B932FkmnI+LI1Z4XEXsiohYRtZGRkV5PBwCYRZ4V+iZJX7J9\nQtJTku6wXS9kKgDAvPUc9IjYERFrI2JU0t2SfhcRY4VNBgCYF74PHQASUcg9RSPi95J+X8TnAgD0\nhhU6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6\nACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSC\noANAIgg6ACSCoANAIgg6ACSi56DbvsH2QdtTtl+1/UCRg3VcuHDhqsdALhFXPwYGSJ4V+nuSvhcR\n6yTdJumbttcXM1bLV3/+B215+IWLEb9w4YK2PPyCvvrzPxR5GixWB3dJB3ZcinhE6/jgrmrnAnrU\nc9Aj4lREvNR+f1rSlKQ1RQ124cIFTZ89r+Onpi9GfcvDL+j4qWlNnz3PSh35REhnz0iHdl+K+oEd\nreOzZ1ipYyA5CviDa3tU0vOSbo6Id670vFqtFo1GY86fNxvxjvWrh7X//tu1ZAnb/8gpG/GOjdul\nzbsku7q5gC62j0REbbbn5a6i7fdL+pWk71wu5ra32W7YbjSbzXl97iVLlmj//bfPeIyYozB2K95Z\nxBwDLFcZbS9XK+ZPRMTTl3tOROyJiFpE1EZGRub1+Tsr9KzsnjqQS2eFnpXdUwcGTJ7vcrGkRyVN\nRcSPihupJbvdsn71sF7/r7u0fvXwjD11oGfZ7ZaN26Wdb7feZvfUgQGTZ4W+SdLXJd1h+2j71xcK\nmktLlizR8NDyGXvm+++/XetXD2t4aDnbLsjHloZWztwz37yrdTy0km0XDKRCvig6V/P9oqjUWqln\n4919DOQSMTPe3cfAAtC3L4qWrTvexByF6o43MccAo44AkAiCDgCJIOgAkAiCDgCJIOgAkAiCDgCJ\nIOgAkAiCDgCJIOgAkAiCDgCJIOgAkAiCDgCJIOgAkAiCDgCJIOgAkAiCDgCJIOgAkAiCDgCJIOgA\nkAiCDgCJIOgAkAiCDgCJIOgAkAiCDgCJIOgAkAiCDgCJIOgAkAiCDgCJIOgAkIhcQbe92fafbL9m\n+8GihlooIuKqxwBwJVX0o+eg214q6WeS7pK0XtLXbK8varCq/fjZP+uh/ccv/iZEhB7af1w/fvbP\nFU8GYKGbPDqpicMTM/oxcXhCk0cnSz1vnhX6JyW9FhGvR8Q5SU9J2lrMWNWKCL1z9rz2vnjiYtQf\n2n9ce188oXfOnmelDuCKIkLT56ZVn6pfjPrE4QnVp+qaPjddaj+W5fjYNZLeyhyflLQx3zgLg219\nf0vrHxt7XzyhvS+ekCTdt2lU39+yXrYrnA7AQmZb4xvGJUn1qbrqU3VJ0ti6MY1vGC+1H3lW6Jeb\n6v/91WN7m+2G7Uaz2cxxuv7KRr2DmAOYi2zUO8qOuZQv6Ccl3ZA5Xivp791Piog9EVGLiNrIyEiO\n0/VXZ5slK7unDgBX0tlmycruqZclT9APS7rJ9o22V0i6W9IzxYxVreye+X2bRvXGri/ovk2jM/bU\nAeBysnvmY+vGdOyeYxpbNzZjT70sPe+hR8R7tr8l6TeSlkp6LCJeLWyyCtnWdUPLZ+yZd7Zfrhta\nzrYLgCuyreEVwzP2zDvbL8Mrhkvth/u52qzVatFoNPp2vrwiYsZ//O5jALiSIvth+0hE1GZ7Hj8p\nehXd//GJOYC5qqIfBB0AEkHQASARBB0AEkHQASARBB0AEkHQASARff0+dNtNSX/t8cNXSfpXgeMM\ngsV2zYvteqXFd82L7XqlYq75PyJi1tdO6WvQ87DdmMs31qdksV3zYrteafFd82K7Xqm/18yWCwAk\ngqADQCIGKeh7qh6gAovtmhfb9UqL75oX2/VKfbzmgdlDBwBc3SCt0AEAVzEQQbe92fafbL9m+8Gq\n5ymT7RtsH7Q9ZftV2w9UPVO/2F5q+2Xb+6uepWy2P2B7n+0/tn+vP1X1TGWz/d32n+lXbD9pe6jq\nmYpm+zHbp22/knnsg7aftf2X9tvryzr/gg+67aWSfibpLknrJX3N9vqrf9RAe0/S9yJinaTbJH0z\n8evNekDSVNVD9MlPJR2IiI9LukWJX7ftNZK+LakWETerdVOcu6udqhS/kLS567EHJT0XETdJeq59\nXIoFH3RJn5T0WkS8HhHnJD0laWvFM5UmIk5FxEvt96fV+h99TbVTlc/2WklflPRI1bOUzfZ1kj4j\n6VFJiohzEfF2tVP1xTJJ77O9TNI1usw9iAddRDwv6d9dD2+V9Hj7/cclfbms8w9C0NdIeitzfFKL\nIHCSZHtU0q2SDlU7SV/8RNK4pAtVD9IHH5XUlLS3vcX0iO1rqx6qTBHxN0k/lPSmpFOSzkTEb6ud\nqm8+HBGnpNaCTdKHyjrRIAT9crf5SP5bc2y/X9KvJH0nIt6pep4y2d4i6XREHKl6lj5ZJukTknZH\nxK2S3lWJ/wxfCNr7xlsl3SjpI5KutT1W7VTpGYSgn5R0Q+Z4rRL8p1qW7eVqxfyJiHi66nn6YJOk\nL9k+odaW2h2269WOVKqTkk5GROdfXvvUCnzKPi/pjYhoRsR5SU9L+nTFM/XLP22vlqT229NlnWgQ\ngn5Y0k22b7S9Qq0vpDxT8UylcevGg49KmoqIH1U9Tz9ExI6IWBsRo2r9/v4uIpJdvUXEPyS9Zftj\n7YfulHS8wpH64U1Jt9m+pv1n/E4l/oXgjGck3dt+/15Jvy7rRMvK+sRFiYj3bH9L0m/U+sr4YxHx\nasVjlWmTpK9L+h/bR9uP/WdE/HeFM6F490t6or1IeV3SfRXPU6qIOGR7n6SX1PpOrpeV4E+N2n5S\n0mclrbJ9UtJOST+Q9Evb31DrL7avlHZ+flIUANIwCFsuAIA5IOgAkAiCDgCJIOgAkAiCDgCJIOgA\nkAiCDgCJIOgAkIj/A2IraoqkPKJ1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07a4e9df98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot2DSet(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz as gv\n",
    "import numbers\n",
    "\n",
    "########## LABELEDSET ##########\n",
    "\n",
    "class LabeledSet:  \n",
    "    \n",
    "    def __init__(self, input_dimension):\n",
    "        self.input_dimension = input_dimension\n",
    "        self.nb_examples = 0\n",
    "    \n",
    "    def addExample(self,vector,label):\n",
    "        if (self.nb_examples == 0):\n",
    "            self.x = np.array([vector])\n",
    "            self.y = np.array([label])\n",
    "        else:\n",
    "            self.x = np.vstack((self.x, vector))\n",
    "            self.y = np.vstack((self.y, label))\n",
    "        \n",
    "        self.nb_examples = self.nb_examples + 1\n",
    "    \n",
    "    #Renvoie la dimension de l'espace d'entrée\n",
    "    def getInputDimension(self):\n",
    "        return self.input_dimension\n",
    "    \n",
    "    #Renvoie le nombre d'exemples dans le set\n",
    "    def size(self):\n",
    "        return self.nb_examples\n",
    "    \n",
    "    #Renvoie la valeur de x_i\n",
    "    def getX(self, i):\n",
    "        return self.x[i]\n",
    "        \n",
    "    \n",
    "    #Renvoie la valeur de y_i\n",
    "    def getY(self, i):\n",
    "        return(self.y[i])\n",
    "    \n",
    "\n",
    "def plot2DSet(set):\n",
    "    \"\"\" LabeledSet -> NoneType\n",
    "        Hypothèse: set est de dimension 2\n",
    "        affiche une représentation graphique du LabeledSet\n",
    "        remarque: l'ordre des labels dans set peut être quelconque\n",
    "    \"\"\"\n",
    "    S_pos = set.x[np.where(set.y == 1),:][0]      # tous les exemples de label +1\n",
    "    S_neg = set.x[np.where(set.y == -1),:][0]     # tous les exemples de label -1\n",
    "    plt.scatter(S_pos[:,0],S_pos[:,1],marker='o')\n",
    "    plt.scatter(S_neg[:,0],S_neg[:,1],marker='x')\n",
    "    \n",
    "##################################\n",
    "\n",
    "########## CLASSIFIEURS ##########\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self,input_dimension):\n",
    "        \"\"\" Constructeur \"\"\"\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    \n",
    "    # Permet de calculer la prediction sur x => renvoie un score\n",
    "    def predict(self,x):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "\n",
    "    \n",
    "    # Permet d'entrainer le modele sur un ensemble de données étiquetés\n",
    "    def train(self,labeledSet):\n",
    "        raise NotImplementedError(\"Please Implement this method\")\n",
    "    \n",
    "    # Permet de calculer le taux de bonne classification\n",
    "    def accuracy(self,set):\n",
    "        nb_ok=0\n",
    "        for i in range(set.size()):\n",
    "            score = self.predict(set.getX(i))\n",
    "            if (score*set.getY(i)>0):\n",
    "                nb_ok = nb_ok+1\n",
    "        acc = nb_ok/(set.size() * 1.0)\n",
    "        return acc    \n",
    "    \n",
    "def plot_frontiere(set,classifier,step=10):\n",
    "    \"\"\" LabeledSet * Classifier * int -> NoneType\n",
    "        Remarque: le 3e argument est optionnel et donne la \"résolution\" du tracé\n",
    "        affiche la frontière de décision associée au classifieur\n",
    "    \"\"\"\n",
    "    mmax=set.x.max(0)\n",
    "    mmin=set.x.min(0)\n",
    "    x1grid,x2grid=np.meshgrid(np.linspace(mmin[0],mmax[0],step),np.linspace(mmin[1],mmax[1],step))\n",
    "    grid=np.hstack((x1grid.reshape(x1grid.size,1),x2grid.reshape(x2grid.size,1)))\n",
    "    \n",
    "    # calcul de la prediction pour chaque point de la grille\n",
    "    res=np.array([classifier.predict(grid[i,:]) for i in range(len(grid)) ])\n",
    "    res=res.reshape(x1grid.shape)\n",
    "    # tracer des frontieres\n",
    "    plt.contourf(x1grid,x2grid,res,colors=[\"red\",\"cyan\"],levels=[-1000,0,1000],linewidth=2)\n",
    "\n",
    "######################################################    \n",
    "    \n",
    "########### Entropie et gain d'information ###########\n",
    "    \n",
    "def classe_majoritaire(labeledSet, labels):\n",
    "    classes_sizes = []\n",
    "    #print(labeledSet.y.tolist())\n",
    "    for label in labels:\n",
    "        classes_sizes.append(len(labeledSet.x[np.where(labeledSet.y == label),:][0]))\n",
    "    \n",
    "    #print(classes_sizes)\n",
    "    return labels[np.argmax(np.array(classes_sizes))]\n",
    "    \n",
    "    \n",
    "def shannon(P):\n",
    "    Hs = 0\n",
    "    k = len(P)\n",
    "    for p_i in P:\n",
    "        tmp = 0\n",
    "        if p_i != 0:\n",
    "            tmp = p_i * log(p_i, k)\n",
    "        Hs += tmp\n",
    "    \n",
    "    #print(P, -Hs)\n",
    "    return -Hs\n",
    "\n",
    "def entropie(labeledSet, labels):\n",
    "    P = []\n",
    "    # récupérer la distribution des classes\n",
    "    for label in labels:\n",
    "        P.append(len(labeledSet.x[np.where(labeledSet.y == label),0:labeledSet.getInputDimension()][0]) / (1.0 * labeledSet.size()))\n",
    "    \n",
    "    # calcul de l'entropie de shannon\n",
    "    return shannon(P)\n",
    "\n",
    "########### Discrétisation des attributs numériques ###########\n",
    "\n",
    "def discretise(LSet, col, labels):\n",
    "    \"\"\" LabelledSet * int -> tuple[float, float]\n",
    "        col est le numéro de colonne sur X à discrétiser\n",
    "        rend la valeur de coupure qui minimise l'entropie ainsi que son entropie.\n",
    "    \"\"\"\n",
    "    # initialisation:\n",
    "    min_entropie = 1.1  # on met à une valeur max car on veut minimiser\n",
    "    min_seuil = 0.0     \n",
    "    # trie des valeurs:\n",
    "    ind= np.argsort(LSet.x,axis=0)\n",
    "    \n",
    "    # calcul des distributions des classes pour E1 et E2:\n",
    "    \n",
    "    inf_labels = [0 for i in range(len(labels))]\n",
    "    sup_labels = [0 for i in range(len(labels))]\n",
    "         \n",
    "    # remarque: au départ on considère que E1 est vide et donc E2 correspond à E. \n",
    "    # Ainsi inf_plus et inf_moins valent 0. Il reste à calculer sup_plus et sup_moins \n",
    "    # dans E.\n",
    "    for j in range(0,LSet.size()):\n",
    "        l = LSet.getY(j)[0]\n",
    "        i = labels.index(l)\n",
    "        sup_labels[i] += 1\n",
    "        \n",
    "    nb_total = 0\n",
    "    for v in sup_labels:\n",
    "        nb_total += v\n",
    "    # nombre d'exemples total dans E\n",
    "    \n",
    "    # parcours pour trouver le meilleur seuil:\n",
    "    for i in range(len(LSet.x)-1):\n",
    "        v_ind_i = ind[i]   # vecteur d'indices (ind_x1, ind_x2, ...)\n",
    "        courant = LSet.getX(v_ind_i[col])[col] # récupérer la valeur de l'attribut col  correspondant à l'indice\n",
    "        lookahead = LSet.getX(ind[i+1][col])[col] # la valeur qui suit\n",
    "        val_seuil = (courant + lookahead) / 2.0; # le seuil\n",
    "        # M-A-J de la distrib. des classes:\n",
    "        # pour réduire les traitements: on retire un exemple de E2 et on le place\n",
    "        # dans E1, c'est ainsi que l'on déplace donc le seuil de coupure.\n",
    "        l = LSet.getY(ind[i][col])[0]# label\n",
    "        \n",
    "        indice = labels.index(l) # indice dans la liste de labels\n",
    "        \n",
    "        inf_labels[indice] += 1\n",
    "        sup_labels[indice] -= 1\n",
    "        \n",
    "        \n",
    "        # calcul de la distribution des classes de chaque côté du seuil:\n",
    "        nb_inf = 0\n",
    "        for v in inf_labels:\n",
    "            nb_inf += v\n",
    "        nb_inf *= 1.0\n",
    "        \n",
    "        nb_sup = 0\n",
    "        for v in sup_labels:\n",
    "            nb_sup += v\n",
    "        nb_sup *= 1.0\n",
    "        \n",
    "        P_inf = []\n",
    "        for v in inf_labels:\n",
    "            P_inf.append(v/nb_inf)\n",
    "        val_entropie_inf = shannon(P_inf)\n",
    "        #print(\"entropie inf: \", val_entropie_inf)\n",
    "        \n",
    "        P_sup = []\n",
    "        for v in sup_labels:\n",
    "            P_sup.append(v/nb_sup)\n",
    "        val_entropie_sup = shannon(P_sup)\n",
    "        #print(\"entropie sup : \", val_entropie_sup)\n",
    "        val_entropie = (nb_inf / nb_total) * val_entropie_inf + (nb_sup / nb_total) * val_entropie_sup\n",
    "        #print(\"entropie : \", val_entropie)\n",
    "        # si cette coupure minimise l'entropie, on mémorise ce seuil et son entropie:\n",
    "        if (min_entropie > val_entropie):\n",
    "            min_entropie = val_entropie\n",
    "            min_seuil = val_seuil\n",
    "    #print(\"min entropie : \", min_entropie)\n",
    "    return (min_seuil, min_entropie)\n",
    "\n",
    "def divise(Lset, att, seuil):\n",
    "    E1 = LabeledSet(Lset.input_dimension)\n",
    "    E2 = LabeledSet(Lset.input_dimension)\n",
    "    \n",
    "    ind= np.argsort(Lset.x,axis=0) # trie les valeurs => ind = tableau des indices\n",
    "    lookahead = -1\n",
    "    \n",
    "    # Séparation des données selon le seuil\n",
    "    for i in range(Lset.size()):\n",
    "        if Lset.getX(i)[att] <= seuil:\n",
    "            E1.addExample(Lset.getX(i), Lset.getY(i))\n",
    "        else:\n",
    "            E2.addExample(Lset.getX(i), Lset.getY(i))\n",
    "    \n",
    "    return E1, E2\n",
    "\n",
    "#################################################\n",
    "\n",
    "########### Représentation d'un arbre ###########\n",
    "\n",
    "class ArbreBinaire:\n",
    "    def __init__(self):\n",
    "        self.attribut = None   # numéro de l'attribut\n",
    "        self.seuil = None\n",
    "        self.inferieur = None # ArbreBinaire Gauche (valeurs <= au seuil)\n",
    "        self.superieur = None # ArbreBinaire Gauche (valeurs > au seuil)\n",
    "        self.classe = None # Classe si c'est une feuille\n",
    "        \n",
    "    def est_feuille(self):\n",
    "        \"\"\" rend True si l'arbre est une feuille \"\"\"\n",
    "        return self.seuil == None\n",
    "    \n",
    "    def ajoute_fils(self,ABinf,ABsup,att,seuil):\n",
    "        \"\"\" ABinf, ABsup: 2 arbres binaires\n",
    "            att: numéro d'attribut\n",
    "            seuil: valeur de seuil\n",
    "        \"\"\"\n",
    "        self.attribut = att\n",
    "        self.seuil = seuil\n",
    "        self.inferieur = ABinf\n",
    "        self.superieur = ABsup\n",
    "    \n",
    "    def ajoute_feuille(self,classe):\n",
    "        \"\"\" classe\n",
    "        \"\"\"\n",
    "        self.classe = classe\n",
    "        \n",
    "    def classifie(self,exemple):\n",
    "        \"\"\" exemple : numpy.array\n",
    "            rend la classe de l'exemple\n",
    "        \"\"\"\n",
    "        if self.est_feuille():\n",
    "            return self.classe\n",
    "        if exemple[self.attribut] <= self.seuil:\n",
    "            return self.inferieur.classifie(exemple)\n",
    "        return self.superieur.classifie(exemple)\n",
    "    \n",
    "    def to_graph(self, g, prefixe='A'):\n",
    "        \"\"\" construit une représentation de l'arbre pour pouvoir\n",
    "            l'afficher\n",
    "        \"\"\"\n",
    "        if self.est_feuille():\n",
    "            g.node(prefixe,str(self.classe),shape='box')\n",
    "        else:\n",
    "            g.node(prefixe, str(self.attribut))\n",
    "            self.inferieur.to_graph(g,prefixe+\"g\")\n",
    "            self.superieur.to_graph(g,prefixe+\"d\")\n",
    "            g.edge(prefixe,prefixe+\"g\", '<='+ str(self.seuil))\n",
    "            g.edge(prefixe,prefixe+\"d\", '>'+ str(self.seuil))\n",
    "        \n",
    "        return g \n",
    "\n",
    "#################################################################### \n",
    "\n",
    "########### Arbre de décision avec attributs catégoriels ###########\n",
    "\n",
    "def divise_categoriel(Lset, att, categories):\n",
    "    nb_cat = len(categories)\n",
    "    E = [LabeledSet(Lset.getInputDimension()) for k in range(nb_cat)]\n",
    "\n",
    "    \n",
    "    n = Lset.size()             \n",
    "\n",
    "    # Séparation des données selon l'attribut catégoriel\n",
    "    for i in range(n):\n",
    "        k = categories.index(Lset.getX(i)[att]) \n",
    "        E[k].addExample(Lset.getX(i), Lset.getY(i))         \n",
    "\n",
    "    return E\n",
    "\n",
    "def entropie_categorielle(LSet, col, categories, labels):\n",
    "    distribution = [list() for i in range(len(labels))]\n",
    "    \n",
    "    #print(\"categories : \", categories)\n",
    "    #print(\"labels : \", labels)\n",
    "    \n",
    "    for c in categories:\n",
    "        nb_label_attr = []\n",
    "        n = 0\n",
    "        for i in range(len(labels)):\n",
    "            l = labels[i]\n",
    "            label_array = LSet.x[(np.where(LSet.y == l)), 0:LSet.getInputDimension()][0] \n",
    "            label_attr = label_array[np.where(label_array[:,col] == c)]\n",
    "            nb_label_attr.append(len(label_attr))\n",
    "            n += len(label_attr)\n",
    "        for i in range(len(labels)):\n",
    "            distribution[i].append(nb_label_attr[i] / (1.0 * n))\n",
    "    \n",
    "    #print(distribution)\n",
    "    min_entropie = 1.1\n",
    "    for i in range(len(categories)):\n",
    "        P = []\n",
    "        for j in range(len(labels)):\n",
    "            P.append(distribution[j][i])\n",
    "        #print(P)\n",
    "        entro = shannon(P)\n",
    "        if min_entropie > entro:\n",
    "            min_entropie = entro\n",
    "    return min_entropie\n",
    "\n",
    "class ArbreCategoriel:\n",
    "    def __init__(self):\n",
    "        self.attribut = None   # numéro de l'attribut\n",
    "        \n",
    "        # arbre générique : attribut catégoriel\n",
    "        self.fils = None\n",
    "\n",
    "        self.classe = None # Classe si c'est une feuille: -1 ou +1\n",
    "        \n",
    "    def est_feuille(self):\n",
    "        \"\"\" rend True si l'arbre est une feuille \"\"\"\n",
    "        return self.attribut == None\n",
    "    \n",
    "    \n",
    "    def ajoute_fils(self,fils,att):\n",
    "        \"\"\" fils: dictionnaire clé=catégorie, valeur=arbre\n",
    "            att: numéro d'attribut\n",
    "        \"\"\"\n",
    "        self.attribut = att\n",
    "        self.fils = fils\n",
    "    \n",
    "    def ajoute_feuille(self,classe):\n",
    "        \"\"\" classe\n",
    "        \"\"\"\n",
    "        self.classe = classe\n",
    "        \n",
    "    def classifie(self,exemple):\n",
    "        \"\"\" exemple : numpy.array\n",
    "            rend la classe de l'exemple\n",
    "        \"\"\"\n",
    "        if self.est_feuille():\n",
    "            return self.classe\n",
    "        else:\n",
    "            for c,f in self.fils.items():\n",
    "                if c == exemple[self.attribut]:\n",
    "                    return f.classifie(exemple)\n",
    "                \n",
    "            \n",
    "    def to_graph(self, g, prefixe='A'):\n",
    "        \"\"\" construit une représentation de l'arbre pour pouvoir\n",
    "            l'afficher\n",
    "        \"\"\"\n",
    "        if self.est_feuille():\n",
    "            g.node(prefixe,str(self.classe),shape='box')\n",
    "        else:\n",
    "            g.node(prefixe, str(self.attribut))\n",
    "            \n",
    "            for c, f in self.fils.items():\n",
    "                f.to_graph(g,prefixe+c)\n",
    "                g.edge(prefixe,prefixe+c, c)\n",
    "        \n",
    "        return g \n",
    "\n",
    "def construit_AD(Lset, epsilon, labels, measure, dsr_measure):\n",
    "    if measure == \"rsdm\":\n",
    "        entro = rsdm(dsr_measure, Lset)\n",
    "    entro = entropie(Lset, labels) \n",
    "    d = Lset.getInputDimension()\n",
    "\n",
    "    if entro <= epsilon:\n",
    "        feuille = ArbreBinaire()\n",
    "        feuille.ajoute_feuille(classe_majoritaire(Lset, labels))\n",
    "        return feuille\n",
    "    else:\n",
    "        min_entropie = 1.1\n",
    "        seuil = 0\n",
    "        attribut = 0\n",
    "        categories = []\n",
    "        for attr in range(d):\n",
    "            if isinstance(Lset.getX(0)[attr], numbers.Real): # attribut numérique\n",
    "                s, entro = discretise(Lset, attr, labels)\n",
    "                if min_entropie > entro:\n",
    "                    min_entropie = entro\n",
    "                    seuil = s\n",
    "                    attribut = attr\n",
    "            else: # attribut catégoriel\n",
    "                # compter le nombre de catégories différentes\n",
    "                n = Lset.size()\n",
    "                cat = [] \n",
    "                distribution = [] # distribution des classes\n",
    "                \n",
    "                for i in range(n):\n",
    "                    c = Lset.getX(i)[attr]\n",
    "                    if c not in cat:\n",
    "                        cat.append(c)\n",
    "                                        \n",
    "                    \n",
    "                # calcul de l'entropie engendrée par ces catégories\n",
    "                entro = entropie_categorielle(Lset, attr, cat, labels)\n",
    "\n",
    "                # garder en mémoire l'attribut et les catégories\n",
    "                if min_entropie > entro:\n",
    "                    attribut = attr\n",
    "                    categories = cat\n",
    "                    \n",
    "        if isinstance(Lset.getX(0)[attribut], numbers.Real):\n",
    "            Linf, Lsup = divise(Lset, attribut, seuil)\n",
    "            AB = ArbreBinaire()\n",
    "            if (Linf.size() != 0 and Lsup.size() != 0):\n",
    "                ABinf = construit_AD(Linf,epsilon, labels)\n",
    "                ABsup = construit_AD(Lsup, epsilon, labels)\n",
    "                AB.ajoute_fils(ABinf,ABsup,attribut, seuil)\n",
    "                return AB\n",
    "            else:\n",
    "                if Lsup.size() == 0:\n",
    "                    AB.ajoute_feuille(classe_majoritaire(Linf, labels))\n",
    "                    return AB\n",
    "                else:\n",
    "                    AB.ajoute_feuille(classe_majoritaire(Lsup, labels))\n",
    "                    return AB\n",
    "        else:\n",
    "            k = len(categories)\n",
    "            E = divise_categoriel(Lset, attribut, categories)\n",
    "            AC = ArbreCategoriel()\n",
    "            fils = dict()\n",
    "            for i in range(k):\n",
    "                fils[categories[i]] = construit_AD(E[i], epsilon, labels)\n",
    "            AC.ajoute_fils(fils, attribut)\n",
    "            \n",
    "            return AC\n",
    "\n",
    "#############################################################\n",
    "\n",
    "class ArbreDecision(Classifier):\n",
    "    # Constructeur\n",
    "    def __init__(self,epsilon, labels, measure):\n",
    "        # valeur seuil d'entropie pour arrêter la construction\n",
    "        self.epsilon= epsilon\n",
    "        self.racine = None\n",
    "        self.labels = labels\n",
    "        self.measure = measure\n",
    "        \n",
    "    # Permet de calculer la prediction sur x => renvoie un score\n",
    "    def predict(self,x):\n",
    "        # classification de l'exemple x avec l'arbre de décision\n",
    "        # on rend 0 (classe -1) ou 1 (classe 1)\n",
    "        classe = self.racine.classifie(x)\n",
    "        return classe\n",
    "    \n",
    "    # Permet d'entrainer le modele sur un ensemble de données\n",
    "    def train(self,set):\n",
    "        # construction de l'arbre de décision \n",
    "        self.set=set\n",
    "        self.racine = construit_AD(set,self.epsilon, self.labels, self.measure)\n",
    "\n",
    "    \n",
    "    # Permet d'afficher l'arbre\n",
    "    def plot(self):\n",
    "        gtree = gv.Digraph(format='png')\n",
    "        return self.racine.to_graph(gtree)        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
